{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x109ab3bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"/Users/Enzo/Downloads/spark/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'# Apache Spark',\n",
       " u'',\n",
       " u'Spark is a fast and general cluster computing system for Big Data. It provides',\n",
       " u'high-level APIs in Scala, Java, Python, and R, and an optimized engine that',\n",
       " u'supports general computation graphs for data analysis. It also supports a',\n",
       " u'rich set of higher-level tools including Spark SQL for SQL and DataFrames,',\n",
       " u'MLlib for machine learning, GraphX for graph processing,',\n",
       " u'and Spark Streaming for stream processing.',\n",
       " u'',\n",
       " u'<http://spark.apache.org/>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'when', 1),\n",
       " (u'alternatively,', 1),\n",
       " (u'\"local\"', 1),\n",
       " (u'including', 4),\n",
       " (u'computation', 1),\n",
       " (u'note', 1),\n",
       " (u'submit', 1),\n",
       " (u'using:', 1),\n",
       " (u'guidance', 2),\n",
       " (u'environment', 1),\n",
       " (u'only', 1),\n",
       " (u'spark](#building-spark).', 1),\n",
       " (u'rich', 1),\n",
       " (u'usage', 1),\n",
       " (u'sc.parallelize(range(1000)).count()', 1),\n",
       " (u'guide,', 1),\n",
       " (u'return', 2),\n",
       " (u'-dskiptests', 1),\n",
       " (u'python', 2),\n",
       " (u'scala,', 1),\n",
       " (u'\"yarn\"', 1),\n",
       " (u'print', 1),\n",
       " (u'not', 1),\n",
       " (u'scala>', 1),\n",
       " (u'and', 10),\n",
       " (u'cluster.', 1),\n",
       " (u'[\"parallel', 1),\n",
       " (u'hive', 2),\n",
       " (u'try', 1),\n",
       " (u'./bin/pyspark', 1),\n",
       " (u'params', 1),\n",
       " (u'through', 1),\n",
       " (u'guide](http://spark.apache.org/contributing.html)', 1),\n",
       " (u'[run', 1),\n",
       " (u'ide,', 1),\n",
       " (u'abbreviated', 1),\n",
       " (u'[project', 1),\n",
       " (u'##', 9),\n",
       " (u'[contribution', 1),\n",
       " (u'library', 1),\n",
       " (u'see', 3),\n",
       " (u'[http://spark.apache.org/developer-tools.html](the', 1),\n",
       " (u'will', 1),\n",
       " (u'#', 1),\n",
       " (u'processing,', 1),\n",
       " (u'for', 15),\n",
       " (u'review', 1),\n",
       " (u'please', 4),\n",
       " (u'contributing', 2),\n",
       " (u'provides', 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Splits each word by each ' ' and puts it in a list\n",
    "# flatmap will gets rid off empty lists, and puts all elements in one list || also puts a 'u' next to each word\n",
    "# 2. map func makes everything lower case and assigns and attaches a 1 to it || ex: [..., (u'spark', 1), ...]\n",
    "# 3. reduce func adds the previous element to the next element if it matches, adds key to it.\n",
    "\n",
    "rdd.flatMap(lambda x: x.split()) \\\n",
    "    .map(lambda x: (x.lower(),1)) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .take(50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
